{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temiloluwa Philip Ojo\n",
    "##  codekagei@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2 solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler,StandardScaler\n",
    "# data splitting into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the defects data\n",
    "android_data = pd.read_csv('./android_traffic.csv')\n",
    "android_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discover the shape\n",
    "\n",
    "print(\"This dataset has {} rows and {} columns\".format(android_data.shape[0],android_data.shape[1]))\n",
    "\n",
    "# discover the datatypes\n",
    "print(android_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = android_data.dtypes\n",
    "print(\"Number categorical featues:\", sum(types=='object'))\n",
    "print(\"Number non-categorical featues: {}\".format(android_data.shape[1] - sum(types == 'object')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description of the data\n",
    "android_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find missing values\n",
    "print(android_data.isna().any().any())\n",
    "\n",
    "# find count of missing values\n",
    "print(android_data.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation of categorical features to integers\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "cat_feats = ['type']\n",
    "encoder.fit(android_data[cat_feats])\n",
    "\n",
    "def ohe_new_features(df, features_name, encoder):\n",
    "    new_feats = encoder.transform(df[features_name])\n",
    "    new_cols = pd.DataFrame(new_feats, dtype=int, columns=encoder.get_feature_names(features_name))\n",
    "    new_df = pd.concat([df, new_cols], axis=1)\n",
    "    new_df.drop(features_name, axis=1, inplace=True)\n",
    "    return new_df\n",
    "\n",
    "android_data = ohe_new_features(android_data,cat_feats,encoder )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding of categorical data completed.\n",
    "android_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate features from target\n",
    "X = android_data.drop(['type_malicious'], axis=1)\n",
    "y = android_data['type_malicious']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.3\n",
    "Before you start building the models, analyze the data (see the number of features,\n",
    "etc.) and tell us whether you expect kNN or SVM to perform better on this problem.\n",
    "Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I expect KNN to perform better for this dataset since it contains a small amount \n",
    "of features which it could be inferred that there is less dimensionality than a dataset with a \n",
    "high number of features and KNN works well with small dataset as it loads all the data into memory\n",
    "while SVM is best for data containing high dimensionality. \n",
    "\n",
    "In addition, there are 7845 training data  and 12 features, this makes KNN more suitable as it \n",
    "does better than SVM when the number of training data is greater than the number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyper parameter tuning\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_neighbors':list(range(1, 10)),\n",
    "              'weights':['distance','uniform'],\n",
    "              'metric':['euclidean', 'manhattan', 'chebyshev', 'cosine']\n",
    "              }\n",
    "\n",
    "grid_search_clf = GridSearchCV(estimator=KNeighborsClassifier(), cv=7, \n",
    "                               scoring='accuracy',param_grid=param_grid\n",
    "                                )\n",
    "\n",
    "grid_search_clf.fit(x_train, y_train)\n",
    "\n",
    "means = grid_search_clf.cv_results_['mean_test_score']\n",
    "stds = grid_search_clf.cv_results_['std_test_score']\n",
    "\n",
    "for mean, std, params in zip(means, stds, grid_search_clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, std * 2, params))\n",
    "    \n",
    "print()\n",
    "print(\"The best parameters set found on development set:\")\n",
    "print()\n",
    "print(grid_search_clf.best_params_)\n",
    "\n",
    "y_pred = grid_search_clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.5 \n",
    "\n",
    "Implement SVM for malware detection. You must perform hyper-parameter tuning\n",
    "for your model on the following hyper-params: {C: np.linspace(1, 2, num=5), kernel:\n",
    "[’rbf ’, ’sigmoid’], gamma: np.logspace(-7, -3, num=5)}. Print the mean score and its\n",
    "standard deviation for each of the built models. Print the best hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # \"Support vector classifier\"\n",
    "\n",
    "# hyper parameter tuning with grid search on SVM\n",
    "param_grid =  {'C': np.linspace(1, 2, num=5), \n",
    "               'kernel': ['rbf', 'sigmoid'], \n",
    "               'gamma': np.logspace(-7, -3, num=5)}\n",
    "\n",
    "grid_search_clf = GridSearchCV(estimator=SVC(),\n",
    "                               cv=7, scoring='accuracy',\n",
    "                               param_grid=param_grid\n",
    "                               )\n",
    "\n",
    "grid_search_clf.fit(x_train, y_train)\n",
    "\n",
    "means = grid_search_clf.cv_results_['mean_test_score']\n",
    "stds = grid_search_clf.cv_results_['std_test_score']\n",
    "\n",
    "for mean, std, params in zip(means, stds, grid_search_clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, std * 2, params))\n",
    "    \n",
    "print()\n",
    "print(\"The best parameters set found on development set:\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(grid_search_clf.best_params_)\n",
    "\n",
    "y_pred = grid_search_clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.6\n",
    "Train both kNN and SVM using the best hyper-parameters on the train set, and print\n",
    "the accuracy on the test set for both models. Do the results support your answer to\n",
    "1.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN model with the best parameters\n",
    "knn_model = KNeighborsClassifier(metric='cosine', n_neighbors=9, weights='distance')\n",
    "\n",
    "knn_model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = knn_model.predict(x_test)\n",
    "\n",
    "knn_model_accuracy_score = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM model with the best parameters\n",
    "svc_model = SVC(C=1.0, gamma=0.001, kernel='rbf')\n",
    "\n",
    "svc_model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = svc_model.predict(x_test)\n",
    "\n",
    "svc_model_accuracy_score = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acccuracy score of both models after application of the best hyper parameters\n",
    "print(\"The accuracy score of the KNN model using the best hyperparameters is: \", knn_model_accuracy_score)\n",
    "\n",
    "print(\"The accuracy score of the SVM model using the best hyperparameters is: \", svc_model_accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "From the above result, the accuracy score of KNN is more than that of SVM. \n",
    "This is in line with my assumption of which model will perform better when observing the \n",
    "count of the total training data and number of features in question **1.3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 \n",
    "Construct a DNN model that has one input layer, one output layer, and 3 hidden\n",
    "layers. The number of nodes in the input layer would be the same as number of\n",
    "statements in the coverage data, whereas the number of nodes in each hidden layer\n",
    "should be simply set as 32. The output layer would have just one node (representing\n",
    "the execution result r) with sigmoid activation function. The activation function in\n",
    "the hidden layers should be the relu function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "coverage_data = pd.read_csv('./coverage.csv')\n",
    "coverage_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discover the shape\n",
    "\n",
    "print(\"This dataset has {} rows and {} columns\".format(coverage_data.shape[0],coverage_data.shape[1]))\n",
    "\n",
    "# discover the datatypes\n",
    "print(coverage_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = coverage_data.drop(['Unnamed: 0','r'], axis=1)\n",
    "y = coverage_data['r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of statements to use for the nodes in the input layer\n",
    "input_layer_size = X.shape[1]\n",
    "batch_size = 10\n",
    "epochs = 30\n",
    "print('The input size is ', input_layer_size)\n",
    "print('The batch size is ', batch_size)\n",
    "print('The epochs is',epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fl_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units=32, input_dim=input_layer_size, activation='relu'))\n",
    "    model.add(Dense(units=32,  activation='relu'))\n",
    "    model.add(Dense(units=32,  activation='relu'))\n",
    "    model.add(Dense(units=1,use_bias=True, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_fl_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2\n",
    "Use the coverage data as the training set to fit/train your DNN model to obtain the\n",
    "complex nonlinear mapping relationship between the coverage data of a test case and\n",
    "its execution result. Regarding the hyper-parameters: Optimizer=Adam(lr=1e-5),\n",
    "epochs=30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optimizer = Adam(lr=1e-5)\n",
    "\n",
    "# compiling the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam_optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(\"Loss:\", loss, \", Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the wrights of the model in hdf5\n",
    "model.save(\"my_model.pth\")\n",
    "model.save(\"my_model.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.3\n",
    "\n",
    "In this step, you will construct the set of virtual test cases. Once again, to get a better\n",
    "understanding of this set, refer to [1]. In summary, this set will have a structure as\n",
    "shown in Figure 2, consisting of the same number of statements as in the coverage\n",
    "data. Note that here each row would represent a virtual test case which covers only\n",
    "one statement of the given computer program. Since each test case only covers one\n",
    "statement, thus the statement would be highly suspicious if the corresponding test\n",
    "case is failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First step is to build a virtual test case data\n",
    "\n",
    "virtual_data = np.zeros((500,500),int)\n",
    "np.fill_diagonal(virtual_data,1)\n",
    "\n",
    "print(\"This virtual dataset has {} rows and {} columns\".format(virtual_data.shape[0],virtual_data.shape[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.4\n",
    "Input the coverage data vector of virtual test set to the trained DNN model and get\n",
    "\n",
    "the output for each test case, which would reflect the probability that its correspond-\n",
    "ing executable statement has a bug. Finally, rank the statements according to the\n",
    "\n",
    "predicted probability scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_on_virtual_data = model.predict(virtual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round the predictions to 2 decimal places to make it easier to work with the data\n",
    "prediction_on_virtual_data = [round(x[0],4) for x in prediction_on_virtual_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(prediction_on_virtual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array containing the statement number and the corresponding suspiciousness\n",
    "\n",
    "state_susp_array = []\n",
    "\n",
    "for i in range(len(prediction_on_virtual_data)):\n",
    "#     since indexes start at 0, 1 is added to each index for the statement\n",
    "    state_susp_array.append([i + 1 , prediction_on_virtual_data[i]])\n",
    "\n",
    "print(state_susp_array[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the statement and suspiciousness according to the suspiciousness\n",
    "# this would make it easy to get the rank of each suspiciousness\n",
    "state_susp_array = sorted(state_susp_array, key=lambda state_susp_array: state_susp_array[1],reverse=True)\n",
    "\n",
    "# after sorting based on suspiciousness\n",
    "print(state_susp_array[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the rank of each statement and append it to the statement and suspiciousness\n",
    "\n",
    "for i in range(len(state_susp_array)):\n",
    "    #     since indexes start at 0, 1 is added to each index for the rank\n",
    "    state_susp_array[i].append(i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state_susp_array[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the data based on the statement\n",
    "\n",
    "state_susp_rank = sorted(state_susp_array, key=lambda state_susp_array: state_susp_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state_susp_rank[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame containing the statement, suspiciousness and rank\n",
    "state_susp_rank_df = pd.DataFrame(state_susp_rank, columns=['Statement','Suspiciousness','Rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_susp_rank_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_susp_rank_df.to_csv('state_susp_rank_df.csv',header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.6\n",
    "(Bonus task) Tune the following hyper-parameters to achieve the best accuracy on a\n",
    "validation split (15% of the training set).\n",
    "- Number of layers.\n",
    "- Number of neurons in each layer.\n",
    "- adding dropout layers.\n",
    "- optimizer and learning rate.\n",
    "- activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each hyper parameter will be fine tuned seperately and used to tune\n",
    "other hyper parameters in order to achieve the best accuracy on a validation split of 15%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Imports\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 hidden layer hyper parameter tuning. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hidden_layer_tuning = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "\n",
    "# Number of neurons\n",
    "# dropout rate\n",
    "# activation function\n",
    "\n",
    "# This is done because tuning more than 3 hyper parameters causes\n",
    "# the host machine to crash\n",
    "\n",
    "# The best hyper parameters gotten will be used to tune the learning rate and optimizer next\n",
    "def dnn_model(dropout_rate=0.0,activation='relu',neurons=1,optimizer='adam',learning_rate=0.001):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=neurons, input_dim=input_layer_size, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn=dnn_model, epochs=30, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "learning_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "neurons = [1, 5, 10, 15, 20, 25, 30,32,64]\n",
    "param_grid = dict(activation=activation,dropout_rate=dropout_rate,\n",
    "                 neurons=neurons,optimizer=optimizer, learning_rate=learning_rate)\n",
    "\n",
    "# pass parameters to grid search\n",
    "\n",
    "grid_cv = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=7)\n",
    "grid_cv_result = grid_cv.fit(X, y, validation_split=0.15)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_cv_result.best_score_, grid_cv_result.best_params_))\n",
    "means = grid_cv_result.cv_results_['mean_test_score']\n",
    "stds = grid_cv_result.cv_results_['std_test_score']\n",
    "params = grid_cv_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "#     saving the best parameters\n",
    "one_hidden_layer_tuning.append(grid_cv_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "# using the best parameters gotten from the previous results\n",
    "# To get the best optimizer for a one layer network\n",
    "def dnn_model(optimizer='adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=one_hidden_layer_tuning[0]['neurons'], input_dim=input_layer_size, activation=one_hidden_layer_tuning[0]['activation']))\n",
    "    model.add(Dropout(one_hidden_layer_tuning[0]['dropout_rate']))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn=dnn_model, epochs=30, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "# learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "# activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "# dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "# neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "\n",
    "# pass parameters to grid search\n",
    "\n",
    "grid_cv = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=7)\n",
    "grid_cv_result = grid_cv.fit(X, y, validation_split=0.15)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_cv_result.best_score_, grid_cv_result.best_params_))\n",
    "means = grid_cv_result.cv_results_['mean_test_score']\n",
    "stds = grid_cv_result.cv_results_['std_test_score']\n",
    "params = grid_cv_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "#     saving the best parameters\n",
    "one_hidden_layer_tuning.append(grid_cv_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "# using the best parameters gotten from the previous results\n",
    "# To get the best learning rate for a one layer network\n",
    "\n",
    "def dnn_model(learn_rate=0.01):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=one_hidden_layer_tuning[0]['neurons'], input_dim=input_layer_size, activation=one_hidden_layer_tuning[0]['activation']))\n",
    "    model.add(Dropout(one_hidden_layer_tuning[0]['dropout_rate']))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    optimizer = RMSprop(learning_rate= learn_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn=dnn_model, epochs=30, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "# optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "# activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "# dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "# neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "param_grid = dict(learn_rate=learn_rate)\n",
    "\n",
    "# pass parameters to grid search\n",
    "\n",
    "grid_cv = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=7)\n",
    "grid_cv_result = grid_cv.fit(X, y, validation_split=0.15)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_cv_result.best_score_, grid_cv_result.best_params_))\n",
    "means = grid_cv_result.cv_results_['mean_test_score']\n",
    "stds = grid_cv_result.cv_results_['std_test_score']\n",
    "params = grid_cv_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "#     saving the best parameters\n",
    "one_hidden_layer_tuning.append(grid_cv_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(one_hidden_layer_tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_hidden_layer_tuning =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "# using the best parameters gotten from the previous results\n",
    "# To get the best learning rate for a two layer network\n",
    "\n",
    "def dnn_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=one_hidden_layer_tuning[0]['neurons'], input_dim=input_layer_size, activation=one_hidden_layer_tuning[0]['activation']))\n",
    "    model.add(Dropout(one_hidden_layer_tuning[0]['dropout_rate']))\n",
    "    model.add(Dense(units=one_hidden_layer_tuning[0]['neurons'], input_dim=input_layer_size, activation=one_hidden_layer_tuning[0]['activation']))\n",
    "    model.add(Dropout(one_hidden_layer_tuning[0]['dropout_rate']))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    optimizer = RMSprop(learning_rate= learn_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn=dnn_model, epochs=30, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "# optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "# activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "# dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "# neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "param_grid = dict(learn_rate=learn_rate)\n",
    "\n",
    "# pass parameters to grid search\n",
    "\n",
    "grid_cv = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=7)\n",
    "grid_cv_result = grid_cv.fit(X, y, validation_split=0.15)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_cv_result.best_score_, grid_cv_result.best_params_))\n",
    "means = grid_cv_result.cv_results_['mean_test_score']\n",
    "stds = grid_cv_result.cv_results_['std_test_score']\n",
    "params = grid_cv_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "#     saving the best parameters\n",
    "one_hidden_layer_tuning.append(grid_cv_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "According to the question, the 1D data has equation y = θ_x + θ_0. Solving for x and equating y to 0 will result in the following equation. x = - θ_0/θ and since λ > 0, the following is possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[A]: Neither high λ or low λ will bring about the prediction rule for A. From the equation above, if λ was negative, it could affect the equation to bring about the linear prediction rule going in the direction of A, but λ > 0. \n",
    "\n",
    "[B]: It could be a normal regression line. A low value of λ( close to 0) could bring about B  by fitting the perfectly to the dataset similar to line B.\n",
    "\n",
    "[C]: Could be produce through a high value of λ by rigde regression. An increase (= infinity) in the ridge regression penalty (λ) will bring about the slope shifting towards a perfect horizontal line similar to line C.\n",
    "\n",
    "[D]: Neither high λ or low λ will cause the prediction rule for D since the highest possible value of lambda will only shift the prediction rule to an horizontal line (slope = 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "From the question, the regularization approach is trying to maximize θ<sub>2<sub>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximizing θ_2 from equation of any linear regression line will result in x_2 = -θ_1x_1/ θ_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[L2]: No, it can't result from the regularization of θ_2 because when θ_2 is regularized, the boundary formed depends less on x2's value making it be more vertical but L2 looks more horizontal. So penalizing θ_2 will not result in L2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[L3]: Yes, regularizing θ_2 could result in L3 boundary as regularizing θ_2 will result in L1\n",
    "coming downwards which could result if C regularization parameter is large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[L4]: No, it can not result from the regularization of θ_2 as this is not the best solution that can be constructed while keeping w2 small and so L4 is not the best solution when regularizing θ_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
